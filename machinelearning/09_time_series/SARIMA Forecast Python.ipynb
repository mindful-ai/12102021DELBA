{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to Forecast with Python Using SARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post, my goal is to give a quick tutorial on how to implement the SARIMA (Seasonal Autoregressive Integrated Moving Average) model to forecast seasonal data using python in Jupyter notebook. If you wish to follow along, please download the the data and code from my GitHub account.\n",
    "\n",
    "Dataset\n",
    "\n",
    "According to the U.S. Energy Information Administration, this data captures the monthly net electricity generation from coal in the country. The numbers are in Kilowatthours. \n",
    "\n",
    "The goal of this exercise is to build a SARIMA model to forecast values till 2030.\n",
    "\n",
    "Importing Dependencies\n",
    "\n",
    "Now, let's start creating the model by importing various libraries in Jupyter notebook that would make our job easier such as numpy, pandas, matplotlib, sklearn, itertools, warnings and statsmodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_log_error\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import warnings\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data\n",
    "\n",
    "In the first step, we will load the dataset using pandas and check the first five elements of the datasheet i.e. head of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data from EIA - Weekly Natural Gas Storage Report\n",
    "data = pd.read_csv('Electricity_Net_Generation_From_Coal_Electric_Power_Sector_Monthly.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Dataset\n",
    "\n",
    "Let's visualize the electricity net generation between 1973 and 2021. The code for producing this visualization is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize net electricity generation from coal since 1973\n",
    "plt.figure(figsize=[12, 5]); # Set dimensions for figure\n",
    "data.plot(x='Date', y='Electricity', figsize = (14, 6), legend = True, color='g')\n",
    "plt.title('Electricity Net Generation From Coal, Electric Power Sector, Monthly')\n",
    "plt.ylabel('Million Kilowatthours')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Stationarity of the Dataset\n",
    "\n",
    "Let us use the Augmented Dickey-Fuller Test, a well known statistical test that can help determine if the time series is stationary. The ADF test is a type of unit root test. Unit roots are a cause for non-stationarity, the ADF test will test if the unit root is present. The Null Hypothesis states there is the presence of a unit root. If the P-Value is less than the Significance Level defined, we reject the Null Hypothesis that the time series contains a unit root. In other words, by rejecting the Null hypothesis, we can conclude that the time series is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented Dickey-Fuller test (ADF Test)\n",
    "ad_fuller_result = adfuller(data['Electricity'])\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differencing\n",
    "\n",
    "Since the series isn't stationary, we will commit to the first order differencing of electricity values and perform ADF test again on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Electricity First Difference'] = data['Electricity'] - data['Electricity'].shift(1)\n",
    "data.dropna(subset = [\"Electricity First Difference\"], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_fuller_result = adfuller(data['Electricity First Difference'])\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Differenced Series \n",
    "\n",
    "The p-value is now less than 0.05, meaning that we can reject the null hypothesis i.e. the time series is stationary. Next, let us visualize the differenced series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12, 5]); # Set dimensions for figure\n",
    "data['Electricity First Difference'].plot()\n",
    "plt.title('Electricity Net Generation From Coal - Differenced Series')\n",
    "plt.ylabel('Million Kilowatthours')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ACF and PACF Plots\n",
    "\n",
    "Now, let us use the statsmodels library to build auto-correlation (ACF) and partial auto-correlation plots from the differenced series. ACF describes how well the present value of the series is related with its past values while PACF finds correlation of the residuals with the next lag value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "import statsmodels.api as sm\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(data['Electricity First Difference'].dropna(),lags=40,ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(data['Electricity First Difference'].dropna(),lags=40,ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SARIMA Model\n",
    "\n",
    "After determining that our time series is stationary, we can use the SARIMA model to predict future values. The model's notation is SARIMA(p, d, q) (P, D, Q)lag. These three parameters account for seasonality, trend, and noise in data. We will use the AIC (Akaike information criterion) indicator which is an estimator of the relative quality of statistical models. The lower the AIC value the better. After performing multiple iterations, the model suggests that SARIMAX(2, 1, 2)x(2, 1, 2, 12) with AIC value of 11413 is the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SARIMAX(data['Electricity'], order=(2, 1, 2), seasonal_order=(2, 1, 2, 12)).fit(dis=-1)\n",
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have fitted the model to the data, we check the residual plots to verify the validity of the model fit. A good forecasting method will have minimal information left in the residuals if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diagnosing the model residuals\n",
    "best_model.plot_diagnostics(figsize=(15,12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlogram on the bottom right suggests that there is no autocorrelation in the residuals, and so they are effectively white noise. Therefore, these residuals are uncorrelated and have close to zero mean.\n",
    "\n",
    "Model Forecast\n",
    "\n",
    "In the forecast step, we will try to predict the electricity generation data for the next 160 steps or 10 years. The graph below shows a good fit compared to historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forecasting 3 years steps ahead\n",
    "forecast_values = best_model.get_forecast(steps = 120)\n",
    "\n",
    "#Confidence intervals of the forecasted values\n",
    "forecast_ci = forecast_values.conf_int()\n",
    "\n",
    "#Plot the data\n",
    "ax = data.plot(x='Date', y='Electricity', figsize = (14, 6), legend = True, color='purple')\n",
    "\n",
    "#Plot the forecasted values \n",
    "forecast_values.predicted_mean.plot(ax=ax, label='Forecast', figsize = (14, 6), grid=True)\n",
    "\n",
    "#Plot the confidence intervals\n",
    "ax.fill_between(forecast_ci.index,\n",
    "                forecast_ci.iloc[: , 0],\n",
    "                forecast_ci.iloc[: , 1], color='yellow', alpha = .5)\n",
    "plt.title('Electricity Net Generation From Coal, Electric Power Sector, Monthly', size = 16)\n",
    "plt.ylabel('KWh', size=12)\n",
    "plt.legend(loc='upper left', prop={'size': 12})\n",
    "ax.axes.get_xaxis().set_visible(True)\n",
    "#annotation\n",
    "ax.text(540, 400, 'Forecasted Values Until 2030', fontsize=12,  color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Validating the Forecast\n",
    "\n",
    "To evaluate the model performance, we calculate the R-squared score and the root mean square error of my dataset to test the authenticity of the model. \n",
    "\n",
    "R Squared gives an indication of how well a model fits a given dataset. It indicates how close the regression line (i.e the predicted values plotted) is to the actual data values. The R squared value lies between 0 and 1 where 0 indicates that this model doesn't fit the given data and 1 indicates that the model fits perfectly to the dataset provided. \n",
    "\n",
    "Root Mean Squared Error (RMSE) is the distance, on average, of a data point from the fitted line, measured along a vertical line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide into train and validation set to calculate R-squared score and mean absolute percentage error \n",
    "train = data[:int(0.85*(len(data)))]\n",
    "test = data[int(0.85*(len(data))):]\n",
    "start=len(train)\n",
    "end=len(train)+len(test)-1\n",
    "predictions = best_model.predict(start=start, end=end, dynamic=False, typ='levels').rename('SARIMA Predictions')\n",
    "evaluation_results = pd.DataFrame({'r2_score': r2_score(test['Electricity'], predictions)}, index=[0])\n",
    "evaluation_results['mean_absolute_error'] = mean_absolute_error(test['Electricity'], predictions)\n",
    "evaluation_results['mean_squared_error'] = mean_squared_error(test['Electricity'], predictions)\n",
    "evaluation_results['root_mean_squared_error'] = np.sqrt(mean_squared_error(test['Electricity'], predictions))\n",
    "evaluation_results['mean_absolute_percentage_error'] = np.mean(np.abs(predictions - test['Electricity'])\n",
    "                                                               /np.abs(test['Electricity']))*100 \n",
    "evaluation_results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "\n",
    "Our model has 90.0% accuracy, which is decent.  \n",
    "\n",
    "The RMSE value of 8056 is directly interpretable in terms of Kilowatthours and is not too high. \n",
    "\n",
    "We can be confident about the model's ability to predict somewhat accurately in the future. We were successfully able to implement the SARIMA method in Python using the Statsmodels library.\n",
    "\n",
    "Thank you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
